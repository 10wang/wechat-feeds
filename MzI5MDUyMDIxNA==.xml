<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>极市平台 | wechat-feeds</title><link>http://MzI5MDUyMDIxNA.favicon.privacyhide.com/favicon.ico</link><description>专注计算机视觉前沿资讯和技术干货，官网：www.cvmart.net</description><managingEditor> (hellodword)</managingEditor><pubDate>Sat, 01 May 2021 19:19:06 +0800</pubDate><image><url>http://MzI5MDUyMDIxNA.favicon.privacyhide.com/favicon.ico</url><title>极市平台 | wechat-feeds</title><link>http://MzI5MDUyMDIxNA.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>“最热”五一弯道超车好机会，有一份CVPR资源大合集请收好！</title><link>https://mp.weixin.qq.com/s/_I5F8zHzSoEy_K6aWsx23g</link><description></description><content:encoded><![CDATA[“最热”五一弯道超车好机会，有一份CVPR资源大合集请收好！]]></content:encoded><pubDate>Sat, 01 May 2021 18:25:15 +0800</pubDate></item><item><title>腾讯/字节/华为/旷视 2022届实习面经—计算机视觉方向</title><link>https://mp.weixin.qq.com/s/2mlHNwXJQZFrddDGSRkkIg</link><description></description><content:encoded><![CDATA[腾讯/字节/华为/旷视 2022届实习面经—计算机视觉方向]]></content:encoded><pubDate>Sat, 01 May 2021 18:25:15 +0800</pubDate></item><item><title>ICML 2021刚刚做出了一个「艰难的决定」：将论文接收率直接砍掉10%</title><link>https://mp.weixin.qq.com/s/8wmSvm1Via0G8MyXgjQZFg</link><description></description><content:encoded><![CDATA[ICML 2021刚刚做出了一个「艰难的决定」：将论文接收率直接砍掉10%]]></content:encoded><pubDate>Sat, 01 May 2021 18:25:15 +0800</pubDate></item><item><title>动态滤波器卷积新高度！DDF：同时解决内容不可知与计算量两大缺陷｜CVPR2021</title><link>https://mp.weixin.qq.com/s/2EexYXVfBQwqH8EG6kHApg</link><description></description><content:encoded><![CDATA[动态滤波器卷积新高度！DDF：同时解决内容不可知与计算量两大缺陷｜CVPR2021]]></content:encoded><pubDate>Fri, 30 Apr 2021 20:54:54 +0800</pubDate></item><item><title>最强无监督行人重识别方法 Cluster Contrast ReID，精度超越有监督算法</title><link>https://mp.weixin.qq.com/s/c7NIGkVyYxiaUWioela8JA</link><description></description><content:encoded><![CDATA[最强无监督行人重识别方法 Cluster Contrast ReID，精度超越有监督算法]]></content:encoded><pubDate>Fri, 30 Apr 2021 20:54:54 +0800</pubDate></item><item><title>实操教程｜5个步骤教你TVM里优化ViT的int8实现，提速4.6倍</title><link>https://mp.weixin.qq.com/s/AGF2hoaFMenu8I9QuxSWOw</link><description></description><content:encoded><![CDATA[实操教程｜5个步骤教你TVM里优化ViT的int8实现，提速4.6倍]]></content:encoded><pubDate>Fri, 30 Apr 2021 20:54:54 +0800</pubDate></item><item><title>计算机视觉算法实习生内推（欢聚时代）</title><link>https://mp.weixin.qq.com/s/oOy5UWAtvN4r4rOVi6wo0w</link><description></description><content:encoded><![CDATA[计算机视觉算法实习生内推（欢聚时代）]]></content:encoded><pubDate>Fri, 30 Apr 2021 20:54:54 +0800</pubDate></item><item><title>IJCAI 2021 放榜：接收率低至13.9%！灭霸式的今年你中了吗</title><link>https://mp.weixin.qq.com/s/Zn74_WRchAomxzhSwWyPsQ</link><description></description><content:encoded><![CDATA[IJCAI 2021 放榜：接收率低至13.9%！灭霸式的今年你中了吗]]></content:encoded><pubDate>Fri, 30 Apr 2021 20:54:54 +0800</pubDate></item><item><title>一文梳理水下目标检测方法</title><link>https://mp.weixin.qq.com/s/UHrYk7_oM0_WBy-FCQXM0g</link><description></description><content:encoded><![CDATA[一文梳理水下目标检测方法]]></content:encoded><pubDate>Thu, 29 Apr 2021 21:26:30 +0800</pubDate></item><item><title>CVPR2021｜Anchor-free新玩法，一个head统一目标检测，实例分割，姿态估计三种任务</title><link>https://mp.weixin.qq.com/s/WhTDs3IENk1gjdp8G9gTgQ</link><description></description><content:encoded><![CDATA[CVPR2021｜Anchor-free新玩法，一个head统一目标检测，实例分割，姿态估计三种任务]]></content:encoded><pubDate>Thu, 29 Apr 2021 21:26:30 +0800</pubDate></item><item><title>极市直播回放丨第78期-田春伟：​基于卷积神经网络的图像复原研究</title><link>https://mp.weixin.qq.com/s/WPD_vlbSpJqk_i243STlug</link><description></description><content:encoded><![CDATA[极市直播回放丨第78期-田春伟：​基于卷积神经网络的图像复原研究]]></content:encoded><pubDate>Thu, 29 Apr 2021 21:26:30 +0800</pubDate></item><item><title>第三届人脸活体检测挑战赛@ICCV2021重磅来袭</title><link>https://mp.weixin.qq.com/s/LPEquBxejUDLvS7WCM0xWA</link><description></description><content:encoded><![CDATA[第三届人脸活体检测挑战赛@ICCV2021重磅来袭]]></content:encoded><pubDate>Thu, 29 Apr 2021 21:26:30 +0800</pubDate></item><item><title>2020亚马逊研究奖公布：陈怡然、陈丹琦、吴佳俊等获奖，华人占比三分之一</title><link>https://mp.weixin.qq.com/s/PVPEdaUSZEfabh5hs4WvDg</link><description></description><content:encoded><![CDATA[2020亚马逊研究奖公布：陈怡然、陈丹琦、吴佳俊等获奖，华人占比三分之一]]></content:encoded><pubDate>Thu, 29 Apr 2021 21:26:30 +0800</pubDate></item><item><title>对比学习（Contrastive Learning）:研究进展精要</title><link>https://mp.weixin.qq.com/s/02j1VLXd5_6tERpBiAvMsQ</link><description></description><content:encoded><![CDATA[对比学习（Contrastive Learning）:研究进展精要]]></content:encoded><pubDate>Wed, 28 Apr 2021 19:44:59 +0800</pubDate></item><item><title>DSRL：灵活而简单的框架,提高网络精度的且不引入额外的计算量,CVPR2020</title><link>https://mp.weixin.qq.com/s/Jr_BrdmXqvdKPkCV41_57A</link><description></description><content:encoded><![CDATA[DSRL：灵活而简单的框架,提高网络精度的且不引入额外的计算量,CVPR2020]]></content:encoded><pubDate>Wed, 28 Apr 2021 19:44:59 +0800</pubDate></item><item><title>实操教程｜我的PyTorch模型比内存还大，怎么训练呀？</title><link>https://mp.weixin.qq.com/s/VZOhV2ET2_c2l57WABddZA</link><description></description><content:encoded><![CDATA[实操教程｜我的PyTorch模型比内存还大，怎么训练呀？]]></content:encoded><pubDate>Wed, 28 Apr 2021 19:44:59 +0800</pubDate></item><item><title>Google发布语义分割新数据集！顺带开发个模型屠榜，已被CVPR2021接收</title><link>https://mp.weixin.qq.com/s/iHsr9rjh3CKupQRDZP-cwg</link><description></description><content:encoded><![CDATA[Google发布语义分割新数据集！顺带开发个模型屠榜，已被CVPR2021接收]]></content:encoded><pubDate>Wed, 28 Apr 2021 19:44:59 +0800</pubDate></item><item><title>搞懂 Vision Transformer 原理和代码，看这篇技术综述就够了（九）</title><link>https://mp.weixin.qq.com/s/JFxwRS3cCeJob120bZEBbA</link><description></description><content:encoded><![CDATA[搞懂 Vision Transformer 原理和代码，看这篇技术综述就够了（九）]]></content:encoded><pubDate>Tue, 27 Apr 2021 21:11:49 +0800</pubDate></item><item><title>一篇综述带你全面了解迁移学习的领域泛化(Domain Generalization)</title><link>https://mp.weixin.qq.com/s/Kr2F2yK34ClnSdmIRnNX_Q</link><description></description><content:encoded><![CDATA[一篇综述带你全面了解迁移学习的领域泛化(Domain Generalization)]]></content:encoded><pubDate>Tue, 27 Apr 2021 21:11:49 +0800</pubDate></item><item><title>美团视觉智能中心招实习生：视觉算法方向</title><link>https://mp.weixin.qq.com/s/rLErsx_r4NsHmNEloHYIMA</link><description></description><content:encoded><![CDATA[美团视觉智能中心招实习生：视觉算法方向]]></content:encoded><pubDate>Tue, 27 Apr 2021 21:11:49 +0800</pubDate></item></channel></rss>