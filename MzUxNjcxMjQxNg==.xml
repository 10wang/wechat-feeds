<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>CVer | wechat-feeds</title><link>http://MzUxNjcxMjQxNg.favicon.privacyhide.com/favicon.ico</link><description>一个专注侃侃计算机视觉方向的公众号。计算机视觉、图像处理、机器学习、深度学习、C/C++、Python、诗和远方等。</description><managingEditor> (hellodword)</managingEditor><pubDate>Wed, 07 Apr 2021 13:27:37 +0800</pubDate><image><url>http://MzUxNjcxMjQxNg.favicon.privacyhide.com/favicon.ico</url><title>CVer | wechat-feeds</title><link>http://MzUxNjcxMjQxNg.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>详解NLP技术中的：Transformer、自注意力机制、预训练模型、图神经网络、模型压缩</title><link>https://mp.weixin.qq.com/s/d8ufxpc8b--Sa3gqW50Ulg</link><description></description><content:encoded><![CDATA[详解NLP技术中的：Transformer、自注意力机制、预训练模型、图神经网络、模型压缩]]></content:encoded><pubDate>Wed, 07 Apr 2021 12:37:59 +0800</pubDate></item><item><title>MoCo v3来了！何恺明团队新作：训练自监督视觉Transformer的实证研究</title><link>https://mp.weixin.qq.com/s/waqkJkwqxU-7utfNnwr2Gg</link><description></description><content:encoded><![CDATA[MoCo v3来了！何恺明团队新作：训练自监督视觉Transformer的实证研究]]></content:encoded><pubDate>Wed, 07 Apr 2021 12:37:59 +0800</pubDate></item><item><title>阿里达摩院提出：首个精度无损的INT8加速训练方案 | AAAI 2021</title><link>https://mp.weixin.qq.com/s/wjwqHPKhYTH3rzwE8GniSg</link><description></description><content:encoded><![CDATA[阿里达摩院提出：首个精度无损的INT8加速训练方案 | AAAI 2021]]></content:encoded><pubDate>Wed, 07 Apr 2021 12:37:59 +0800</pubDate></item><item><title>因买不到RTX 3090！他花19万搭了一个专业级机器学习工作站</title><link>https://mp.weixin.qq.com/s/13mK4DHjzpjZtWdZPleWzQ</link><description></description><content:encoded><![CDATA[因买不到RTX 3090！他花19万搭了一个专业级机器学习工作站]]></content:encoded><pubDate>Wed, 07 Apr 2021 12:37:59 +0800</pubDate></item><item><title>又一所三本院校，变身985大学！</title><link>https://mp.weixin.qq.com/s/_V3-FtMle9bB6QXj72EPUg</link><description></description><content:encoded><![CDATA[又一所三本院校，变身985大学！]]></content:encoded><pubDate>Wed, 07 Apr 2021 12:37:59 +0800</pubDate></item><item><title>四年前离开百度的吴恩达，现在上市了！</title><link>https://mp.weixin.qq.com/s/f6H6FmpcHFvKtv-silVXnA</link><description></description><content:encoded><![CDATA[四年前离开百度的吴恩达，现在上市了！]]></content:encoded><pubDate>Mon, 05 Apr 2021 22:00:24 +0800</pubDate></item><item><title>连华为都在研究的方向，到底有多牛?</title><link>https://mp.weixin.qq.com/s/66MBS95RYHFYnWnvDY2G3A</link><description></description><content:encoded><![CDATA[连华为都在研究的方向，到底有多牛?]]></content:encoded><pubDate>Mon, 05 Apr 2021 22:00:24 +0800</pubDate></item><item><title>87.7%准确率！CvT：将卷积引入视觉Transformer</title><link>https://mp.weixin.qq.com/s/P3xBi7ZfwzAs1i_yGaWEUA</link><description></description><content:encoded><![CDATA[87.7%准确率！CvT：将卷积引入视觉Transformer]]></content:encoded><pubDate>Mon, 05 Apr 2021 22:00:24 +0800</pubDate></item><item><title>一文看尽微信AI团队打造&#34;扫一扫&#34;植物识别利器</title><link>https://mp.weixin.qq.com/s/fDZldJ5kQVZlM3aMm3JKRg</link><description></description><content:encoded><![CDATA[一文看尽微信AI团队打造"扫一扫"植物识别利器]]></content:encoded><pubDate>Mon, 05 Apr 2021 22:00:24 +0800</pubDate></item><item><title>男子清华姚班毕业！月薪五万，网上征婚，却屡遭遇嘲讽……</title><link>https://mp.weixin.qq.com/s/e5gY2Bu2fW52HCRdaceHbA</link><description></description><content:encoded><![CDATA[男子清华姚班毕业！月薪五万，网上征婚，却屡遭遇嘲讽……]]></content:encoded><pubDate>Mon, 05 Apr 2021 22:00:24 +0800</pubDate></item><item><title>955 不加班的公司名单：955.WLB</title><link>https://mp.weixin.qq.com/s/LOWNQLrER5d5UTDH4WGqLA</link><description></description><content:encoded><![CDATA[955 不加班的公司名单：955.WLB]]></content:encoded><pubDate>Mon, 05 Apr 2021 21:36:55 +0800</pubDate></item><item><title>学NLP的人跑去CVPR投稿！中了顶会一作，还是一位本科生...</title><link>https://mp.weixin.qq.com/s/fBffA0ntRz_SUL9NQflx9g</link><description></description><content:encoded><![CDATA[学NLP的人跑去CVPR投稿！中了顶会一作，还是一位本科生...]]></content:encoded><pubDate>Mon, 05 Apr 2021 21:36:55 +0800</pubDate></item><item><title>超实用性！哈工大提出ACNet：用于超分辨的非对称卷积神经网络</title><link>https://mp.weixin.qq.com/s/FNpurdPInb_trvgDNYpjwQ</link><description></description><content:encoded><![CDATA[超实用性！哈工大提出ACNet：用于超分辨的非对称卷积神经网络]]></content:encoded><pubDate>Mon, 05 Apr 2021 21:36:55 +0800</pubDate></item><item><title>1篇SCI一区/2篇二区认定E1博士，送130㎡住房，副教授待遇，硕士配偶入事业编，60万安家费</title><link>https://mp.weixin.qq.com/s/M9K1ss80U70gXmZVOzG7Ng</link><description></description><content:encoded><![CDATA[1篇SCI一区/2篇二区认定E1博士，送130㎡住房，副教授待遇，硕士配偶入事业编，60万安家费]]></content:encoded><pubDate>Mon, 05 Apr 2021 21:36:55 +0800</pubDate></item><item><title>关于NLP相关技术全部在这里：预训练模型、图神经网络、模型压缩、知识图谱、信息抽取、序列模型、深度学习、语法分析、文本处理</title><link>https://mp.weixin.qq.com/s/VpcHIpy9EqjIhg8xSlJ4ZA</link><description></description><content:encoded><![CDATA[关于NLP相关技术全部在这里：预训练模型、图神经网络、模型压缩、知识图谱、信息抽取、序列模型、深度学习、语法分析、文本处理]]></content:encoded><pubDate>Sun, 04 Apr 2021 12:12:56 +0800</pubDate></item><item><title>不使用标签数据! 自动搜索CNN-Transformer混合结构，速度超过EfficientNet 2.1%！</title><link>https://mp.weixin.qq.com/s/4yODj8rjMf_jTdf67Zi9Sg</link><description></description><content:encoded><![CDATA[不使用标签数据! 自动搜索CNN-Transformer混合结构，速度超过EfficientNet 2.1%！]]></content:encoded><pubDate>Sun, 04 Apr 2021 12:12:56 +0800</pubDate></item><item><title>CVPR 2021 | 利用时序差分进行动作识别的最新Backbone：TDN</title><link>https://mp.weixin.qq.com/s/6z6uR3v1hy335R6BYaKjeg</link><description></description><content:encoded><![CDATA[CVPR 2021 | 利用时序差分进行动作识别的最新Backbone：TDN]]></content:encoded><pubDate>Sun, 04 Apr 2021 12:12:56 +0800</pubDate></item><item><title>阿联酋起源人工智能研究院（IIAI）诚邀优秀人才加盟</title><link>https://mp.weixin.qq.com/s/9iqeLd5eXaQfiwS_HtS4XQ</link><description></description><content:encoded><![CDATA[阿联酋起源人工智能研究院（IIAI）诚邀优秀人才加盟]]></content:encoded><pubDate>Sun, 04 Apr 2021 12:12:56 +0800</pubDate></item><item><title>重大布局！北京大学，落子上海！</title><link>https://mp.weixin.qq.com/s/UAe9f15Gp55F_lA4J8xYog</link><description></description><content:encoded><![CDATA[重大布局！北京大学，落子上海！]]></content:encoded><pubDate>Sun, 04 Apr 2021 12:12:56 +0800</pubDate></item><item><title>中国已消失的九所世界级大学</title><link>https://mp.weixin.qq.com/s/tBDniSLKx0k7O0AHPUkeEQ</link><description></description><content:encoded><![CDATA[中国已消失的九所世界级大学]]></content:encoded><pubDate>Fri, 02 Apr 2021 23:39:30 +0800</pubDate></item></channel></rss>