<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>机器学习研究组订阅 | wechat-feeds</title><link>http://MzU1NTUxNTM0Mg.favicon.privacyhide.com/favicon.ico</link><description>机器学习研究会由百度七剑客雷鸣先生创办，旨在推动AI的技术发展和产业落地。参与组织北大、清华”AI前沿与产业趋势“公开课，广泛的和高校、企业、创业、VC开展合作，自身也参与优秀AI项目的投资和孵化。</description><managingEditor> (hellodword)</managingEditor><pubDate>Sun, 28 Mar 2021 19:19:23 +0800</pubDate><image><url>http://MzU1NTUxNTM0Mg.favicon.privacyhide.com/favicon.ico</url><title>机器学习研究组订阅 | wechat-feeds</title><link>http://MzU1NTUxNTM0Mg.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>70分钟了解图神经网络，图注意力网络一作带来最「自然」的GNN讲解</title><link>https://mp.weixin.qq.com/s/ujkEfV977wRUrxCMVKkcXA</link><description></description><content:encoded><![CDATA[70分钟了解图神经网络，图注意力网络一作带来最「自然」的GNN讲解]]></content:encoded><pubDate>Sun, 28 Mar 2021 18:30:25 +0800</pubDate></item><item><title>Nature重磅起底「论文工厂」，1300多篇嫌疑文章大批量造假！</title><link>https://mp.weixin.qq.com/s/6muG_PfqtB57uJbIiS_1ag</link><description></description><content:encoded><![CDATA[Nature重磅起底「论文工厂」，1300多篇嫌疑文章大批量造假！]]></content:encoded><pubDate>Sun, 28 Mar 2021 18:30:25 +0800</pubDate></item><item><title>那些年，我们一起追过的Backbone</title><link>https://mp.weixin.qq.com/s/ExQkaN7uTOHoo9s_xvevbw</link><description></description><content:encoded><![CDATA[那些年，我们一起追过的Backbone]]></content:encoded><pubDate>Sun, 28 Mar 2021 18:30:25 +0800</pubDate></item><item><title>AutoML大提速，谷歌开源自动化寻找最优ML模型新平台Model Search</title><link>https://mp.weixin.qq.com/s/nprd_pqY_IdZGe-69jPTeA</link><description></description><content:encoded><![CDATA[AutoML大提速，谷歌开源自动化寻找最优ML模型新平台Model Search]]></content:encoded><pubDate>Sat, 27 Mar 2021 19:44:10 +0800</pubDate></item><item><title>英伟达让GPU挖矿效率减半，显卡却未必更好抢</title><link>https://mp.weixin.qq.com/s/VQv8HWUGvSwU8pQeOkbutQ</link><description></description><content:encoded><![CDATA[英伟达让GPU挖矿效率减半，显卡却未必更好抢]]></content:encoded><pubDate>Sat, 27 Mar 2021 19:44:10 +0800</pubDate></item><item><title>用 Keras 实现使用自归一化神经网络来解决梯度消失的问题</title><link>https://mp.weixin.qq.com/s/poHI6FeGF8S6qTrFHA9Ziw</link><description></description><content:encoded><![CDATA[用 Keras 实现使用自归一化神经网络来解决梯度消失的问题]]></content:encoded><pubDate>Sat, 27 Mar 2021 19:44:10 +0800</pubDate></item><item><title>超越卷积、自注意力机制：强大的神经网络新算子involution</title><link>https://mp.weixin.qq.com/s/H4s13vPESjzXAYQhEnLDHA</link><description></description><content:encoded><![CDATA[超越卷积、自注意力机制：强大的神经网络新算子involution]]></content:encoded><pubDate>Fri, 26 Mar 2021 20:19:08 +0800</pubDate></item><item><title>「黄道12宫杀手」51年前密码信破解过程首度公开！但凶手身份仍是谜</title><link>https://mp.weixin.qq.com/s/ik9Kjjur4RT75BnJV0hWsg</link><description></description><content:encoded><![CDATA[「黄道12宫杀手」51年前密码信破解过程首度公开！但凶手身份仍是谜]]></content:encoded><pubDate>Fri, 26 Mar 2021 20:19:08 +0800</pubDate></item><item><title>实现图深度学习复杂研究性质任务太头疼？这个新工具包帮你应对</title><link>https://mp.weixin.qq.com/s/lAymj-r0uACN0Rj0zYOTVA</link><description></description><content:encoded><![CDATA[实现图深度学习复杂研究性质任务太头疼？这个新工具包帮你应对]]></content:encoded><pubDate>Fri, 26 Mar 2021 20:19:08 +0800</pubDate></item><item><title>时隔两年，黑洞又有了新照片，还是高清的</title><link>https://mp.weixin.qq.com/s/zifi6d7NIKJ78X3U340DuA</link><description></description><content:encoded><![CDATA[时隔两年，黑洞又有了新照片，还是高清的]]></content:encoded><pubDate>Thu, 25 Mar 2021 19:27:52 +0800</pubDate></item><item><title>苹果大战泄密人：库克推迟发布会「找奸细」，爆料人被「逼」剃光眉毛！</title><link>https://mp.weixin.qq.com/s/FcSgRKVfCzSUngcZU-MZiw</link><description></description><content:encoded><![CDATA[苹果大战泄密人：库克推迟发布会「找奸细」，爆料人被「逼」剃光眉毛！]]></content:encoded><pubDate>Thu, 25 Mar 2021 19:27:52 +0800</pubDate></item><item><title>从 SimCLR 到 BarLow Twins ，一文了解自监督学习不断打脸的认知发展史</title><link>https://mp.weixin.qq.com/s/caXc-uS8Ahqfr2YY4xYdLg</link><description></description><content:encoded><![CDATA[从 SimCLR 到 BarLow Twins ，一文了解自监督学习不断打脸的认知发展史]]></content:encoded><pubDate>Thu, 25 Mar 2021 19:27:52 +0800</pubDate></item><item><title>深度图像修复的回顾和改进：使用生成对抗网络基于Patch的图像修复</title><link>https://mp.weixin.qq.com/s/BjQOEPxDlFaXpq9-GIbwDw</link><description></description><content:encoded><![CDATA[深度图像修复的回顾和改进：使用生成对抗网络基于Patch的图像修复]]></content:encoded><pubDate>Wed, 24 Mar 2021 19:32:29 +0800</pubDate></item><item><title>哈佛、MIT学者联手，创下矩阵乘法运算最快纪录</title><link>https://mp.weixin.qq.com/s/849VQ6Lrc8zfUamjVuoHKg</link><description></description><content:encoded><![CDATA[哈佛、MIT学者联手，创下矩阵乘法运算最快纪录]]></content:encoded><pubDate>Wed, 24 Mar 2021 19:32:29 +0800</pubDate></item><item><title>最新！全球学术排名出炉：21 所中国大学位居世界 100 强</title><link>https://mp.weixin.qq.com/s/ugCJhH2dAKUvEHpQitgezQ</link><description></description><content:encoded><![CDATA[最新！全球学术排名出炉：21 所中国大学位居世界 100 强]]></content:encoded><pubDate>Wed, 24 Mar 2021 19:32:29 +0800</pubDate></item><item><title>基于深度学习的图像匹配技术一览</title><link>https://mp.weixin.qq.com/s/Gccgs1dxkUj1LsU7ipP-4Q</link><description></description><content:encoded><![CDATA[基于深度学习的图像匹配技术一览]]></content:encoded><pubDate>Tue, 23 Mar 2021 20:02:56 +0800</pubDate></item><item><title>莆田版GPT-3开源：同等复现预训练模型GPT Neo，可在Colab上完成微调</title><link>https://mp.weixin.qq.com/s/qu3HckNQkgoNo8GTPS_TMg</link><description></description><content:encoded><![CDATA[莆田版GPT-3开源：同等复现预训练模型GPT Neo，可在Colab上完成微调]]></content:encoded><pubDate>Tue, 23 Mar 2021 20:02:56 +0800</pubDate></item><item><title>收藏 | 图解最常用的10个机器学习算法！</title><link>https://mp.weixin.qq.com/s/J5qquTEKLD72_n_EJKa3Kw</link><description></description><content:encoded><![CDATA[收藏 | 图解最常用的10个机器学习算法！]]></content:encoded><pubDate>Tue, 23 Mar 2021 20:02:56 +0800</pubDate></item><item><title>【预告】北大AI第二讲：创新工场首席科学家周明 -- 预训练模型的进展</title><link>https://mp.weixin.qq.com/s/KesHcNP-FG6Oi_YQCFFrNg</link><description></description><content:encoded><![CDATA[【预告】北大AI第二讲：创新工场首席科学家周明 -- 预训练模型的进展]]></content:encoded><pubDate>Mon, 22 Mar 2021 20:27:29 +0800</pubDate></item><item><title>3的三个整数立方和有多少个解？全球40万台计算机助力，MIT研究登上PNAS</title><link>https://mp.weixin.qq.com/s/NZnNvE-b9WPNimaHa-SOqg</link><description></description><content:encoded><![CDATA[3的三个整数立方和有多少个解？全球40万台计算机助力，MIT研究登上PNAS]]></content:encoded><pubDate>Mon, 22 Mar 2021 20:27:29 +0800</pubDate></item></channel></rss>