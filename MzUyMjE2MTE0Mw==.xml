<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>机器学习算法工程师 | wechat-feeds</title><link>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</link><description>机器学习、深度学习、数据挖掘等人工智能领域的技术实战干货文章，这里都有！分享从业经验是我们的不变的准则……</description><managingEditor> (hellodword)</managingEditor><pubDate>Tue, 23 Feb 2021 13:03:34 +0800</pubDate><image><url>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</url><title>机器学习算法工程师 | wechat-feeds</title><link>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>你真的学懂过C++吗？</title><link>https://mp.weixin.qq.com/s/XOYRq5vk0BEofDgFjgEMnQ</link><description></description><content:encoded><![CDATA[你真的学懂过C++吗？]]></content:encoded><pubDate>Mon, 22 Feb 2021 15:20:02 +0800</pubDate></item><item><title>AI 框架基础技术之自动求导机制 (Autograd)</title><link>https://mp.weixin.qq.com/s/Mc20umSpz_onnCR3ASDCPw</link><description></description><content:encoded><![CDATA[AI 框架基础技术之自动求导机制 (Autograd)]]></content:encoded><pubDate>Mon, 22 Feb 2021 15:20:02 +0800</pubDate></item><item><title>太辛苦的钱，我建议你不要挣</title><link>https://mp.weixin.qq.com/s/q21eJhtMNBGgkybImyXAfA</link><description></description><content:encoded><![CDATA[太辛苦的钱，我建议你不要挣]]></content:encoded><pubDate>Sat, 20 Feb 2021 13:21:56 +0800</pubDate></item><item><title>今天来捋一捋pytorch官方Faster R-CNN代码</title><link>https://mp.weixin.qq.com/s/Wvmf4vDRqf2QJjCQEhYKUA</link><description></description><content:encoded><![CDATA[今天来捋一捋pytorch官方Faster R-CNN代码]]></content:encoded><pubDate>Sat, 20 Feb 2021 13:21:56 +0800</pubDate></item><item><title>如何通过 SparrowRecsys，搭建一套完整的深度学习推荐系统</title><link>https://mp.weixin.qq.com/s/Ky0TVZr9uGm3l-LfGmeAAA</link><description></description><content:encoded><![CDATA[如何通过 SparrowRecsys，搭建一套完整的深度学习推荐系统]]></content:encoded><pubDate>Fri, 19 Feb 2021 15:49:04 +0800</pubDate></item><item><title>机器学习已成为过去？</title><link>https://mp.weixin.qq.com/s/hc36Fbst4o3SEOG5o3EnVA</link><description></description><content:encoded><![CDATA[机器学习已成为过去？]]></content:encoded><pubDate>Tue, 16 Feb 2021 14:58:08 +0800</pubDate></item><item><title>OpenAI又放大招：连接文本与图像的CLIP，在ImageNet上效果媲美ResNet50</title><link>https://mp.weixin.qq.com/s/VKzferpWMDJIK0-GFoCgvQ</link><description></description><content:encoded><![CDATA[OpenAI又放大招：连接文本与图像的CLIP，在ImageNet上效果媲美ResNet50]]></content:encoded><pubDate>Tue, 16 Feb 2021 14:58:08 +0800</pubDate></item><item><title>各位小伙伴们新春快乐：三本电子书送你打发时间！</title><link>https://mp.weixin.qq.com/s/jAtySC5lEywaCT1QPkAtVQ</link><description></description><content:encoded><![CDATA[各位小伙伴们新春快乐：三本电子书送你打发时间！]]></content:encoded><pubDate>Thu, 11 Feb 2021 11:00:12 +0800</pubDate></item><item><title>Transformer为何能闯入CV界秒杀CNN？</title><link>https://mp.weixin.qq.com/s/atMQOVBLnVpNgkofOemghg</link><description></description><content:encoded><![CDATA[Transformer为何能闯入CV界秒杀CNN？]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>从源码学习Transformer！</title><link>https://mp.weixin.qq.com/s/FwB6wHqHQ1Zs9_02Uj4upA</link><description></description><content:encoded><![CDATA[从源码学习Transformer！]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>2021年，我终于决定入门GCN</title><link>https://mp.weixin.qq.com/s/BJWOTk91H-qLdQRiqaCo-g</link><description></description><content:encoded><![CDATA[2021年，我终于决定入门GCN]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>你真的理解GPT吗？</title><link>https://mp.weixin.qq.com/s/1S1a_Xl0XSRMY6k7_qbGLw</link><description></description><content:encoded><![CDATA[你真的理解GPT吗？]]></content:encoded><pubDate>Sun, 07 Feb 2021 22:38:43 +0800</pubDate></item><item><title>Focal Loss和它背后的男人RetinaNet</title><link>https://mp.weixin.qq.com/s/RCQxvNUyfHkygbEfqJN89w</link><description></description><content:encoded><![CDATA[Focal Loss和它背后的男人RetinaNet]]></content:encoded><pubDate>Sun, 07 Feb 2021 22:38:43 +0800</pubDate></item><item><title>AI 框架基础技术之自动求导机制 (Autograd)</title><link>https://mp.weixin.qq.com/s/uILglTKH9IbhoC-LPnHpnQ</link><description></description><content:encoded><![CDATA[AI 框架基础技术之自动求导机制 (Autograd)]]></content:encoded><pubDate>Thu, 04 Feb 2021 21:23:14 +0800</pubDate></item><item><title>！！龙泉寺贤超法师：用 AI 为古籍经书识别、断句、翻译</title><link>https://mp.weixin.qq.com/s/Xok-s0yvpgf9Wfo5zn_MUw</link><description></description><content:encoded><![CDATA[！！龙泉寺贤超法师：用 AI 为古籍经书识别、断句、翻译]]></content:encoded><pubDate>Thu, 04 Feb 2021 21:23:14 +0800</pubDate></item><item><title>ICLR2021自蒸馏方法SEED：显著提升小模型性能</title><link>https://mp.weixin.qq.com/s/fHGKHx7-hU86ID8qaN9oEw</link><description></description><content:encoded><![CDATA[ICLR2021自蒸馏方法SEED：显著提升小模型性能]]></content:encoded><pubDate>Wed, 03 Feb 2021 21:50:44 +0800</pubDate></item><item><title>涨点神器FixRes：两次超越ImageNet数据集上的SOTA</title><link>https://mp.weixin.qq.com/s/Nzvrx_gYwFI8KuPO6B2PQA</link><description></description><content:encoded><![CDATA[涨点神器FixRes：两次超越ImageNet数据集上的SOTA]]></content:encoded><pubDate>Wed, 03 Feb 2021 21:50:44 +0800</pubDate></item><item><title>FcaNet：从频域角度重新思考注意力机制</title><link>https://mp.weixin.qq.com/s/c3X6KzX3TQ3BgVqjf1WKWA</link><description></description><content:encoded><![CDATA[FcaNet：从频域角度重新思考注意力机制]]></content:encoded><pubDate>Tue, 02 Feb 2021 21:48:04 +0800</pubDate></item><item><title>Transformer为何能闯入CV界秒杀CNN？</title><link>https://mp.weixin.qq.com/s/hujm2Zo-jxQfWWGBDOzaPg</link><description></description><content:encoded><![CDATA[Transformer为何能闯入CV界秒杀CNN？]]></content:encoded><pubDate>Tue, 02 Feb 2021 21:48:04 +0800</pubDate></item></channel></rss>