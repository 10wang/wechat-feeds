<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>机器学习算法工程师 | wechat-feeds</title><link>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</link><description>机器学习、深度学习、数据挖掘等人工智能领域的技术实战干货文章，这里都有！分享从业经验是我们的不变的准则……</description><managingEditor> (hellodword)</managingEditor><pubDate>Thu, 11 Feb 2021 11:30:11 +0800</pubDate><image><url>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</url><title>机器学习算法工程师 | wechat-feeds</title><link>http://MzUyMjE2MTE0Mw.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>各位小伙伴们新春快乐：三本电子书送你打发时间！</title><link>https://mp.weixin.qq.com/s/jAtySC5lEywaCT1QPkAtVQ</link><description></description><content:encoded><![CDATA[各位小伙伴们新春快乐：三本电子书送你打发时间！]]></content:encoded><pubDate>Thu, 11 Feb 2021 11:00:12 +0800</pubDate></item><item><title>Transformer为何能闯入CV界秒杀CNN？</title><link>https://mp.weixin.qq.com/s/atMQOVBLnVpNgkofOemghg</link><description></description><content:encoded><![CDATA[Transformer为何能闯入CV界秒杀CNN？]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>从源码学习Transformer！</title><link>https://mp.weixin.qq.com/s/FwB6wHqHQ1Zs9_02Uj4upA</link><description></description><content:encoded><![CDATA[从源码学习Transformer！]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>2021年，我终于决定入门GCN</title><link>https://mp.weixin.qq.com/s/BJWOTk91H-qLdQRiqaCo-g</link><description></description><content:encoded><![CDATA[2021年，我终于决定入门GCN]]></content:encoded><pubDate>Mon, 08 Feb 2021 23:16:40 +0800</pubDate></item><item><title>你真的理解GPT吗？</title><link>https://mp.weixin.qq.com/s/1S1a_Xl0XSRMY6k7_qbGLw</link><description></description><content:encoded><![CDATA[你真的理解GPT吗？]]></content:encoded><pubDate>Sun, 07 Feb 2021 22:38:43 +0800</pubDate></item><item><title>Focal Loss和它背后的男人RetinaNet</title><link>https://mp.weixin.qq.com/s/RCQxvNUyfHkygbEfqJN89w</link><description></description><content:encoded><![CDATA[Focal Loss和它背后的男人RetinaNet]]></content:encoded><pubDate>Sun, 07 Feb 2021 22:38:43 +0800</pubDate></item><item><title>AI 框架基础技术之自动求导机制 (Autograd)</title><link>https://mp.weixin.qq.com/s/uILglTKH9IbhoC-LPnHpnQ</link><description></description><content:encoded><![CDATA[AI 框架基础技术之自动求导机制 (Autograd)]]></content:encoded><pubDate>Thu, 04 Feb 2021 21:23:14 +0800</pubDate></item><item><title>！！龙泉寺贤超法师：用 AI 为古籍经书识别、断句、翻译</title><link>https://mp.weixin.qq.com/s/Xok-s0yvpgf9Wfo5zn_MUw</link><description></description><content:encoded><![CDATA[！！龙泉寺贤超法师：用 AI 为古籍经书识别、断句、翻译]]></content:encoded><pubDate>Thu, 04 Feb 2021 21:23:14 +0800</pubDate></item><item><title>ICLR2021自蒸馏方法SEED：显著提升小模型性能</title><link>https://mp.weixin.qq.com/s/fHGKHx7-hU86ID8qaN9oEw</link><description></description><content:encoded><![CDATA[ICLR2021自蒸馏方法SEED：显著提升小模型性能]]></content:encoded><pubDate>Wed, 03 Feb 2021 21:50:44 +0800</pubDate></item><item><title>涨点神器FixRes：两次超越ImageNet数据集上的SOTA</title><link>https://mp.weixin.qq.com/s/Nzvrx_gYwFI8KuPO6B2PQA</link><description></description><content:encoded><![CDATA[涨点神器FixRes：两次超越ImageNet数据集上的SOTA]]></content:encoded><pubDate>Wed, 03 Feb 2021 21:50:44 +0800</pubDate></item><item><title>FcaNet：从频域角度重新思考注意力机制</title><link>https://mp.weixin.qq.com/s/c3X6KzX3TQ3BgVqjf1WKWA</link><description></description><content:encoded><![CDATA[FcaNet：从频域角度重新思考注意力机制]]></content:encoded><pubDate>Tue, 02 Feb 2021 21:48:04 +0800</pubDate></item><item><title>Transformer为何能闯入CV界秒杀CNN？</title><link>https://mp.weixin.qq.com/s/hujm2Zo-jxQfWWGBDOzaPg</link><description></description><content:encoded><![CDATA[Transformer为何能闯入CV界秒杀CNN？]]></content:encoded><pubDate>Tue, 02 Feb 2021 21:48:04 +0800</pubDate></item><item><title>送书活动来啦 | 最新IT学习书单，共5本！免费送！</title><link>https://mp.weixin.qq.com/s/3tOZG76ltbLcDd4imVnPYw</link><description></description><content:encoded><![CDATA[送书活动来啦 | 最新IT学习书单，共5本！免费送！]]></content:encoded><pubDate>Mon, 01 Feb 2021 12:13:46 +0800</pubDate></item><item><title>今天来捋一捋pytorch官方Faster R-CNN代码</title><link>https://mp.weixin.qq.com/s/Lt6ISeS-O0np5LDSSVY9yg</link><description></description><content:encoded><![CDATA[今天来捋一捋pytorch官方Faster R-CNN代码]]></content:encoded><pubDate>Mon, 01 Feb 2021 12:13:46 +0800</pubDate></item><item><title>重磅开源！FAIR发布自监督训练库VISSL！</title><link>https://mp.weixin.qq.com/s/b-w_jUqxGR7hY19auiar-A</link><description></description><content:encoded><![CDATA[重磅开源！FAIR发布自监督训练库VISSL！]]></content:encoded><pubDate>Fri, 29 Jan 2021 21:02:08 +0800</pubDate></item><item><title>留言送书丨深度迁移学习方法的基本思路</title><link>https://mp.weixin.qq.com/s/Yzbn8B9DsBErt9VbAQTY3w</link><description></description><content:encoded><![CDATA[留言送书丨深度迁移学习方法的基本思路]]></content:encoded><pubDate>Thu, 28 Jan 2021 22:42:19 +0800</pubDate></item><item><title>SWA：让你的目标检测模型无痛涨点1% AP</title><link>https://mp.weixin.qq.com/s/yALfhpCJ6kJSfdugldjOsQ</link><description></description><content:encoded><![CDATA[SWA：让你的目标检测模型无痛涨点1% AP]]></content:encoded><pubDate>Thu, 28 Jan 2021 22:42:19 +0800</pubDate></item><item><title>涨点神器FixRes：两次超越ImageNet数据集上的SOTA</title><link>https://mp.weixin.qq.com/s/LJNKrPV3z4EOOHe0r9tDQA</link><description></description><content:encoded><![CDATA[涨点神器FixRes：两次超越ImageNet数据集上的SOTA]]></content:encoded><pubDate>Wed, 27 Jan 2021 22:58:36 +0800</pubDate></item></channel></rss>