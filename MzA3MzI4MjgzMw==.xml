<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>机器之心 | wechat-feeds</title><link>http://MzA3MzI4MjgzMw.favicon.privacyhide.com/favicon.ico</link><description>专业的人工智能媒体和产业服务平台</description><managingEditor> (hellodword)</managingEditor><pubDate>Fri, 07 May 2021 13:24:33 +0800</pubDate><image><url>http://MzA3MzI4MjgzMw.favicon.privacyhide.com/favicon.ico</url><title>机器之心 | wechat-feeds</title><link>http://MzA3MzI4MjgzMw.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>全球首款2纳米制程芯片问世：每平方毫米3.3亿晶体管，IBM打造</title><link>https://mp.weixin.qq.com/s/siqfKpTy7pjCI8swIqdEag</link><description></description><content:encoded><![CDATA[全球首款2纳米制程芯片问世：每平方毫米3.3亿晶体管，IBM打造]]></content:encoded><pubDate>Fri, 07 May 2021 12:28:15 +0800</pubDate></item><item><title>Michael Jordan、Sutton、Silver等人，刚刚入选英国皇家学会会士</title><link>https://mp.weixin.qq.com/s/e-tegIOipeUjGET1hdVCpw</link><description></description><content:encoded><![CDATA[Michael Jordan、Sutton、Silver等人，刚刚入选英国皇家学会会士]]></content:encoded><pubDate>Fri, 07 May 2021 12:28:15 +0800</pubDate></item><item><title>两层线性层结构超越自注意机制，清华计图团队提出External Attention</title><link>https://mp.weixin.qq.com/s/MxcZzqqqc2Qhc4tqy9KsAQ</link><description></description><content:encoded><![CDATA[两层线性层结构超越自注意机制，清华计图团队提出External Attention]]></content:encoded><pubDate>Fri, 07 May 2021 12:28:15 +0800</pubDate></item><item><title>自动生成模型动画：北大神经融合形状新方法登上SIGGRAPH 2021</title><link>https://mp.weixin.qq.com/s/7o0oyHpYQtDdwhlbZjkKSw</link><description></description><content:encoded><![CDATA[自动生成模型动画：北大神经融合形状新方法登上SIGGRAPH 2021]]></content:encoded><pubDate>Fri, 07 May 2021 12:28:15 +0800</pubDate></item><item><title>从通用型到业务型，中文大模型时代下NLP预训练的创新与实践</title><link>https://mp.weixin.qq.com/s/s4l03EUcnVUYazkSzaA1Xw</link><description></description><content:encoded><![CDATA[从通用型到业务型，中文大模型时代下NLP预训练的创新与实践]]></content:encoded><pubDate>Fri, 07 May 2021 12:28:15 +0800</pubDate></item><item><title>MLP回归，无需卷积、自注意力，纯多层感知机视觉架构媲美CNN、ViT</title><link>https://mp.weixin.qq.com/s/rFMfG-lc5oybXa3f11ie2g</link><description></description><content:encoded><![CDATA[MLP回归，无需卷积、自注意力，纯多层感知机视觉架构媲美CNN、ViT]]></content:encoded><pubDate>Thu, 06 May 2021 12:55:42 +0800</pubDate></item><item><title>首次成功着陆：SpaceX星舰试飞实现突破</title><link>https://mp.weixin.qq.com/s/Bvk-jZ4tbi3jXfDkYwiMlQ</link><description></description><content:encoded><![CDATA[首次成功着陆：SpaceX星舰试飞实现突破]]></content:encoded><pubDate>Thu, 06 May 2021 12:55:42 +0800</pubDate></item><item><title>清华计图开源：智能P图神器DeepFaceEditing</title><link>https://mp.weixin.qq.com/s/5tvtI7NmHwjzXtayzncHpw</link><description></description><content:encoded><![CDATA[清华计图开源：智能P图神器DeepFaceEditing]]></content:encoded><pubDate>Thu, 06 May 2021 12:55:42 +0800</pubDate></item><item><title>你的「在看」有人看，清华研究者从微信「看一看」里发现了这些规律</title><link>https://mp.weixin.qq.com/s/gXy5n3_CebjzIwwNeCUNyA</link><description></description><content:encoded><![CDATA[你的「在看」有人看，清华研究者从微信「看一看」里发现了这些规律]]></content:encoded><pubDate>Thu, 06 May 2021 12:55:42 +0800</pubDate></item><item><title>论AI学霸的自我修养，吴飞、贾扬清「高能」圆桌对话</title><link>https://mp.weixin.qq.com/s/tZIapToQ5XetPi0T7mk2Rg</link><description></description><content:encoded><![CDATA[论AI学霸的自我修养，吴飞、贾扬清「高能」圆桌对话]]></content:encoded><pubDate>Thu, 06 May 2021 12:55:42 +0800</pubDate></item><item><title>Transformer作者创建，Hinton、李飞飞、Goodfellow等大佬投资，这家新公司要做什么？</title><link>https://mp.weixin.qq.com/s/QE98Fb7b96mMARMgIiJ96Q</link><description></description><content:encoded><![CDATA[Transformer作者创建，Hinton、李飞飞、Goodfellow等大佬投资，这家新公司要做什么？]]></content:encoded><pubDate>Wed, 05 May 2021 12:04:49 +0800</pubDate></item><item><title>使用Kubernetes，一个人如何支撑起创业公司运作？</title><link>https://mp.weixin.qq.com/s/f9hhouhLlJ3FUauALBABGQ</link><description></description><content:encoded><![CDATA[使用Kubernetes，一个人如何支撑起创业公司运作？]]></content:encoded><pubDate>Wed, 05 May 2021 12:04:49 +0800</pubDate></item><item><title>50年前，一场茶话会上提出的超图边着色猜想终获证明：颜色数永远少于顶点数</title><link>https://mp.weixin.qq.com/s/wfw693LCBSWnxAszPD9JXw</link><description></description><content:encoded><![CDATA[50年前，一场茶话会上提出的超图边着色猜想终获证明：颜色数永远少于顶点数]]></content:encoded><pubDate>Wed, 05 May 2021 12:04:49 +0800</pubDate></item><item><title>语言模型微调领域有哪些最新进展？一文详解最新趋势</title><link>https://mp.weixin.qq.com/s/XVZSAxaWM30t9rOeXYM03A</link><description></description><content:encoded><![CDATA[语言模型微调领域有哪些最新进展？一文详解最新趋势]]></content:encoded><pubDate>Wed, 05 May 2021 12:04:49 +0800</pubDate></item><item><title>再造一个「谷歌大脑」？Samy Bengio加入苹果：将领导全新AI研究部门</title><link>https://mp.weixin.qq.com/s/AOpRD8YMt5X-2cF4cQcrqw</link><description></description><content:encoded><![CDATA[再造一个「谷歌大脑」？Samy Bengio加入苹果：将领导全新AI研究部门]]></content:encoded><pubDate>Tue, 04 May 2021 11:40:08 +0800</pubDate></item><item><title>人工神经网络秒变脉冲神经网络，新技术有望开启边缘AI计算新时代</title><link>https://mp.weixin.qq.com/s/9cLJphsHYKGt7RvKtqYvsg</link><description></description><content:encoded><![CDATA[人工神经网络秒变脉冲神经网络，新技术有望开启边缘AI计算新时代]]></content:encoded><pubDate>Tue, 04 May 2021 11:40:08 +0800</pubDate></item><item><title>加入联邦学习的客户端设备——随机选择真的好吗？</title><link>https://mp.weixin.qq.com/s/3io-nP9ycnGCVKlMRRSjcA</link><description></description><content:encoded><![CDATA[加入联邦学习的客户端设备——随机选择真的好吗？]]></content:encoded><pubDate>Tue, 04 May 2021 11:40:08 +0800</pubDate></item><item><title>PyPy为什么能让Python比C还快？一文了解内在机制</title><link>https://mp.weixin.qq.com/s/kPqrjreM753_lEI2jkxz6w</link><description></description><content:encoded><![CDATA[PyPy为什么能让Python比C还快？一文了解内在机制]]></content:encoded><pubDate>Tue, 04 May 2021 11:40:08 +0800</pubDate></item><item><title>马斯克脑机接口公司Neuralink高层动荡：联合创始人兼总裁离职，曾想建侏罗纪公园</title><link>https://mp.weixin.qq.com/s/NFSkDCUz2ByveBngzlubQQ</link><description></description><content:encoded><![CDATA[马斯克脑机接口公司Neuralink高层动荡：联合创始人兼总裁离职，曾想建侏罗纪公园]]></content:encoded><pubDate>Mon, 03 May 2021 11:57:14 +0800</pubDate></item><item><title>找到反例！博士后数学家推翻困扰数学界80多年的单位猜想</title><link>https://mp.weixin.qq.com/s/vDTnJrQTO7jT590NeZxOcQ</link><description></description><content:encoded><![CDATA[找到反例！博士后数学家推翻困扰数学界80多年的单位猜想]]></content:encoded><pubDate>Mon, 03 May 2021 11:57:14 +0800</pubDate></item></channel></rss>