<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AINLP | wechat-feeds</title><link>http://MjM5ODkzMzMwMQ.favicon.privacyhide.com/favicon.ico</link><description>一个有趣有AI的自然语言处理社区：关注AI、NLP、机器学习、推荐系统、计算广告等相关技术。公众号可直接对话双语聊天机器人，尝试自动对联、作诗机、藏头诗生成器，调戏夸夸机器人、彩虹屁生成器，使用中英翻译，查询相似词，测试NLP相关工具包。</description><managingEditor> (hellodword)</managingEditor><pubDate>Tue, 16 Feb 2021 23:18:31 +0800</pubDate><image><url>http://MjM5ODkzMzMwMQ.favicon.privacyhide.com/favicon.ico</url><title>AINLP | wechat-feeds</title><link>http://MjM5ODkzMzMwMQ.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>从0开始搭建深度学习框架，知道原理后竟然这么简单！</title><link>https://mp.weixin.qq.com/s/Udn7ycb3QMb899itOvi4uA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/sz_mmbiz_jpg/jCVxvrjcLyKh7vzWVrk4cwZvDmMicsyE75q8VPrD7exkvwnJbiaVKn0JXYTHPRf9YiabDgokHrOMQ9RLS4M6ZjiaNQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>2020国内深度学习框架领域百花齐放。各大公司也都陆续推出了自己的框架，大大推动了深度学习的发展。]]></content:encoded><pubDate>Tue, 16 Feb 2021 17:34:26 +0800</pubDate></item><item><title>深度融合 | 当推荐系统遇见知识图谱</title><link>https://mp.weixin.qq.com/s/mjkJY9yH2rizJi-huxan1g</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQer9AiaDoApo6sWia1oPk6DaicdLqrA3lDibcyo7kyJM0dVVadoj382Aykkh0KcA5KQicWNjpBC7OB1kzQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>NewBeeNLP原创出品   公众号专栏作者@上杉翔二  悠闲会 · 信息检索上次我们看了『推荐系统 +]]></content:encoded><pubDate>Tue, 16 Feb 2021 17:34:26 +0800</pubDate></item><item><title>推荐实践之召回算法梳理与优化思考</title><link>https://mp.weixin.qq.com/s/8aG20jIxKQrwMKMn39eN1Q</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/sz_mmbiz_jpg/6SwztUGIp9fQKU48qyFVb3H0bm85zavHDBG99TV14CBLH40pCXypRNIjueVcXV8ib3YgrrxcnCJyCIvIvV3ouibg/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>在 推荐精排模型之经典排序模型一文中，我们谈到工业推荐系统一般包含四个环节，分别是召回、粗排、精排和重排。召]]></content:encoded><pubDate>Tue, 16 Feb 2021 17:34:26 +0800</pubDate></item><item><title>盘点高效的KNN实现算法</title><link>https://mp.weixin.qq.com/s/pStfyM9o8jnBz_mleecrJQ</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/V23nFVyYSrCnvX5K8u2KdpWQp067NXUqVD3qJYk3qVAD9icFaMmzLFUmYJBYN8z7k7Oicy973p7pnVHhwPYaVt3Q/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>1967年，斯坦福大学的两位研究员Cover和Hart，以《战国策》中 “物以类聚，人以群分”的思想，提出了]]></content:encoded><pubDate>Tue, 16 Feb 2021 17:34:26 +0800</pubDate></item><item><title>图神经网络综述（二）</title><link>https://mp.weixin.qq.com/s/VclMA4lGEB5e_-eRg9RJug</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/sz_mmbiz_jpg/cs8SE66bpicgDCDtkYMKSS9juXGUN3XIQV3JK9xibMhG8qicBtcnExbudR8KfkEs7sKmljG5NoN07JeqP8XKOt0ew/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>]]></content:encoded><pubDate>Tue, 16 Feb 2021 17:34:26 +0800</pubDate></item><item><title>我的第一篇论文诞生的故事</title><link>https://mp.weixin.qq.com/s/9AvA8FOEf91S7R_9QBzFwg</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YKUgTHPeJWT4XlNQP6ZcjmUtzRN7jCymmO9XibJWic3fmdmgRKwVz0icibVY9rGIicILp1ytx4f4YBpOFQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>我的第一篇论文诞生的故事作者：郭必扬时间：2020-12-16前言：离上一次写博文已经快半年了，这半年我主要]]></content:encoded><pubDate>Mon, 15 Feb 2021 22:57:21 +0800</pubDate></item><item><title>AoAFFM:Attention+FFM强强组合</title><link>https://mp.weixin.qq.com/s/8SiPrDGlrDwP55U3muTJ-g</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/O1QwZavS4bNibXR5WNnMzqjdAuhe2eiaFS1NhK2WhPzickTNCNkBqm6mzJtXd3NnOE0Bww7AmoKYkib0QrICKlSdyQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>Attention-over-Attention Field-Aware Factorization Mac]]></content:encoded><pubDate>Mon, 15 Feb 2021 22:57:21 +0800</pubDate></item><item><title>图嵌入表示TADW：当DeepWalk加上外部文本信息</title><link>https://mp.weixin.qq.com/s/njg0jYc6SorTbD1S3P8MEA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQeoazQuS8SvR8k0KxVOvejibg16nEYu60pJbDNRVKibjLvxB1m5iaxxcE81G1U5X5BwZezA8NVDsfksg/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>Graph Embedding系列文章的第四篇]]></content:encoded><pubDate>Mon, 15 Feb 2021 22:57:21 +0800</pubDate></item><item><title>元学习综述 | 进入Meta Learning的世界(一)</title><link>https://mp.weixin.qq.com/s/46nvCl5o4QYvRemzOrnaoQ</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/WC0sXokAH7BeYSdkS1dwmuA3NNnZ1FMzlxkUxSyLTRN6lZD3jywLDr7X6ZxunpPEyYeBqiblFE83zRt0yqgsLaA/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>]]></content:encoded><pubDate>Mon, 15 Feb 2021 22:57:21 +0800</pubDate></item><item><title>跨界出圈 | 谈谈BERT跨模态预训练</title><link>https://mp.weixin.qq.com/s/KaZHAIbKzVcJM5ZQiULivA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQdWcvPicpCOzNx5cSEpDcRlaXPNUiaZe9zRz6SGA9xk3T5HCsJSUh3X6mQN0G7Th43w6MEZzWaxKicUg/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>Bert跨模态]]></content:encoded><pubDate>Sat, 13 Feb 2021 22:52:39 +0800</pubDate></item><item><title>自然语言处理领域的数据增广方法</title><link>https://mp.weixin.qq.com/s/gANDD_mr23cebClXm4Cn2w</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/58FUuNaBUjrqLyyHCWCiahicERibcoczVCcEyNEoSy514OLflzfZWWSKuDCZHKKoJ3UwWsGvecfUw5Bxz7iakgGibzQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>自然语言处理领域的数据增广方法]]></content:encoded><pubDate>Sat, 13 Feb 2021 22:52:39 +0800</pubDate></item><item><title>多目标学习(MMOE/ESMM/PLE)在推荐系统的实战经验分享</title><link>https://mp.weixin.qq.com/s/9deheqOevdGyqTPJH8l-ng</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/5MlptuibhwKJVkh02HHSIskP42vGEJO5T0XkwySN0gicED6Mg8fk4DOQBSqKvVQE7V581QveLHpic7IUP9icd9gn0Q/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>多目标学习]]></content:encoded><pubDate>Sat, 13 Feb 2021 22:52:39 +0800</pubDate></item><item><title>一份最新的、全面的NLP文本分类综述</title><link>https://mp.weixin.qq.com/s/P0p1mEPZXuqtcSRsU5WdIA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahKMg4bs6IpoP7cQKicfNFz7oU6r5x692wufkWUSFF8zQvR9sLfuo3e0BycVNyeHjBZJOlpbdGibibBQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>Paper：Deep Learning Based Text Classification: A Compr]]></content:encoded><pubDate>Fri, 12 Feb 2021 22:12:19 +0800</pubDate></item><item><title>推荐粗排（召回）工程实践之双塔DNN模型</title><link>https://mp.weixin.qq.com/s/AVePXHWZW8AydyTrMN_TYg</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/sz_mmbiz_jpg/6SwztUGIp9ecmyKtXurVb8j1xpMxLiarUZVkgdp3yMvxVJRicGUYBM1WxE7Q5icDgwbJoYBVOBAdkVOmWwwoJqrIA/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>粗排作用在 推荐精排模型之经典排序模型 一文中我们介绍了工业推荐系统中主要包括召回、粗排、精排、重排这四个环]]></content:encoded><pubDate>Fri, 12 Feb 2021 22:12:19 +0800</pubDate></item><item><title>拼手速红包，先到先得</title><link>https://mp.weixin.qq.com/s/J1oHXH9r8o2Hay1QwUiRMA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKukFNyfAFq6s4XfhZVD1l2pTlulsFicE1VvfMlkXJ4SGAhDuzRdf8ACsZRyrueUjMFTfjYRdC7M9g/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>感谢大家对AINLP的支持，发个支付宝口令红包，总计999元，300个随机红包，无套路，拼手速，先到先得。祝]]></content:encoded><pubDate>Thu, 11 Feb 2021 21:36:10 +0800</pubDate></item><item><title>Transformer的一家！</title><link>https://mp.weixin.qq.com/s/Z2W66OziBkMhufNBvnKlGQ</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/CuZzSF5jYZww7ickxMqMYzx54UY4aYSE3NFVbuCvRr3NTqCSzicbiciaibsBZqzsgdmIlolWUUcmOxgny0FzgrLzlzA/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>瞧，Transformer一家]]></content:encoded><pubDate>Wed, 10 Feb 2021 22:25:52 +0800</pubDate></item><item><title>以算法岗为例：我最想对入职前的自己说些什么？</title><link>https://mp.weixin.qq.com/s/70wXQIqAEeJScSzhKkJitw</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/6xW2D94qBjH9ajY7GH9nzYLVDzEUFpKeXP6ibbXlqTqB96IWImeEiaNxPRGib69ktFEczic6LJcWzIk2UVXZ40Gsicw/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>元旦伊始没有来得及去写一下总结，那就趁着春节开始前的最后一个假期总结一下吧。进入算法岗的正式工作虽然只有半年]]></content:encoded><pubDate>Wed, 10 Feb 2021 22:25:52 +0800</pubDate></item><item><title>快速从无到有建模完成思路</title><link>https://mp.weixin.qq.com/s/LimJC6Hw7wEDB9FitBNMkA</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPyQt3YrTNVzxD5p3bicT1s0neTEhhIR27s03nQ6lXmKVw0iclGvXx4ZqZmXZgvf4bQCRrmvZxlBrTOQ/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>【ML&DEV】这是大家没有看过的船新栏目！ML表示机器学习，DEV表示开发，本专栏旨在为大家分享作为算法工]]></content:encoded><pubDate>Wed, 10 Feb 2021 22:25:52 +0800</pubDate></item><item><title>那一年，让我整个人升华的C++ BERT项目</title><link>https://mp.weixin.qq.com/s/emvQOJNMnf0QqsjcqD6M7w</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/AzuXfeINxjXf3rQypdmlCbd23l2HiatNBt8oXwajgn5pKQDbbUbY3eQLTjj8r3gEe9l66TX9PVciaoHKXYZlQMIw/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>你的编程能力从什么时候开始突飞猛进？]]></content:encoded><pubDate>Wed, 10 Feb 2021 22:25:52 +0800</pubDate></item><item><title>模型压缩与蒸馏！BERT的忒修斯船</title><link>https://mp.weixin.qq.com/s/VZEm2m75HZSeez3n4hBZuw</link><description></description><content:encoded><![CDATA[<img src="http://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQdwUpM2z7RPdZQzgib8ic7Fl8zxQiaM8kiapYia2o38y8eibShv1uOF9JBjIDAcC5iarAgjVYV5v5Eib58Ecg/0?wx_fmt=jpeg" referrerpolicy="no-referrer"><br>模型压缩与蒸馏]]></content:encoded><pubDate>Tue, 09 Feb 2021 20:37:20 +0800</pubDate></item></channel></rss>