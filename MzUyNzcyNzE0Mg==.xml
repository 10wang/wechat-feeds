<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>深度学习与图网络 | wechat-feeds</title><link>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</link><description>关注图网络、图表示学习，最近顶会顶刊动态以及机器学习基本方法，包括无监督学习、半监督学习、弱监督学习、元学习等</description><managingEditor> (hellodword)</managingEditor><pubDate>Tue, 01 Jun 2021 12:42:25 +0800</pubDate><image><url>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</url><title>深度学习与图网络 | wechat-feeds</title><link>http://MzUyNzcyNzE0Mg.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>每天2小时，吃透 985博士总结的这份保姆级TensorFlow + PyTorch笔记（20G高清/PPT/代码)</title><link>https://mp.weixin.qq.com/s/JwAdAV7uNQ3ADavZ8HTEtw</link><description></description><content:encoded><![CDATA[每天2小时，吃透 985博士总结的这份保姆级TensorFlow + PyTorch笔记（20G高清/PPT/代码)]]></content:encoded><pubDate>Tue, 01 Jun 2021 11:44:39 +0800</pubDate></item><item><title>最新「图机器学习药物发现」综述论文，22页pdf245篇文献阐述GML如何建模生物医学</title><link>https://mp.weixin.qq.com/s/dXEzOfarEWVfB371B3GJnQ</link><description></description><content:encoded><![CDATA[最新「图机器学习药物发现」综述论文，22页pdf245篇文献阐述GML如何建模生物医学]]></content:encoded><pubDate>Mon, 31 May 2021 23:18:48 +0800</pubDate></item><item><title>ICML2021 | 有向图网络Directional Graph Networks(在锌上分子上误差减少了11%到32%))</title><link>https://mp.weixin.qq.com/s/ng-uublEpRxbh_qfkHI8Wg</link><description></description><content:encoded><![CDATA[ICML2021 | 有向图网络Directional Graph Networks(在锌上分子上误差减少了11%到32%))]]></content:encoded><pubDate>Mon, 31 May 2021 23:18:48 +0800</pubDate></item><item><title>WWW21 | RetaGNN：用于时序/顺序推荐的图神经网络(最大提升达29%)</title><link>https://mp.weixin.qq.com/s/7Oo7Qm3wREFSj07Ba2lj5g</link><description></description><content:encoded><![CDATA[WWW21 | RetaGNN：用于时序/顺序推荐的图神经网络(最大提升达29%)]]></content:encoded><pubDate>Sun, 30 May 2021 22:24:13 +0800</pubDate></item><item><title>Awesome!!! 2021年最新最全图学习,图神经网络综述</title><link>https://mp.weixin.qq.com/s/-PxhutNrDafvQAMMNCggFA</link><description></description><content:encoded><![CDATA[Awesome!!! 2021年最新最全图学习,图神经网络综述]]></content:encoded><pubDate>Sun, 30 May 2021 22:24:13 +0800</pubDate></item><item><title>从零搭建基于知识图谱的问答系统（以医疗行业为例）</title><link>https://mp.weixin.qq.com/s/En0weGtqrJ-8_pHCGrvI9A</link><description></description><content:encoded><![CDATA[从零搭建基于知识图谱的问答系统（以医疗行业为例）]]></content:encoded><pubDate>Fri, 28 May 2021 10:21:41 +0800</pubDate></item><item><title>2021最新五篇图网络研究综述, 涉及AutoML, 自监督学习，鲁棒表示，元学习等</title><link>https://mp.weixin.qq.com/s/EdOzxxEEnFbDtgbs7-tR4A</link><description></description><content:encoded><![CDATA[2021最新五篇图网络研究综述, 涉及AutoML, 自监督学习，鲁棒表示，元学习等]]></content:encoded><pubDate>Fri, 28 May 2021 10:21:41 +0800</pubDate></item><item><title>CS224W图机器学习课，斯坦福大牛主讲 | 视频、课件</title><link>https://mp.weixin.qq.com/s/-p4mys3rLrTSnIITufqa5A</link><description></description><content:encoded><![CDATA[CS224W图机器学习课，斯坦福大牛主讲 | 视频、课件]]></content:encoded><pubDate>Thu, 27 May 2021 07:20:22 +0800</pubDate></item><item><title>Amazing! 从“几何深度学习”看深度学习江湖的统一</title><link>https://mp.weixin.qq.com/s/8zGCN4X_5E-YhY1tMXjSzQ</link><description></description><content:encoded><![CDATA[Amazing! 从“几何深度学习”看深度学习江湖的统一]]></content:encoded><pubDate>Thu, 27 May 2021 07:20:22 +0800</pubDate></item><item><title>探索未来 | AI 盛会 | 智源大会带你刷新“世界第一”记录！</title><link>https://mp.weixin.qq.com/s/UPhGMXBqyT1Yp6-8DwPRRw</link><description></description><content:encoded><![CDATA[探索未来 | AI 盛会 | 智源大会带你刷新“世界第一”记录！]]></content:encoded><pubDate>Thu, 27 May 2021 07:20:22 +0800</pubDate></item><item><title>顶会最新趋势公布，这个论文方向成最大赢家！</title><link>https://mp.weixin.qq.com/s/UQDkqiaGlzQcS6Y3Lzuvmw</link><description></description><content:encoded><![CDATA[顶会最新趋势公布，这个论文方向成最大赢家！]]></content:encoded><pubDate>Wed, 26 May 2021 18:38:09 +0800</pubDate></item><item><title>KDD2021 | 左右互搏：基于协同对比学习的自监督异质图神经网络</title><link>https://mp.weixin.qq.com/s/QRTw-WlBDEFVIDBCFu-n_g</link><description></description><content:encoded><![CDATA[KDD2021 | 左右互搏：基于协同对比学习的自监督异质图神经网络]]></content:encoded><pubDate>Wed, 26 May 2021 18:38:09 +0800</pubDate></item><item><title>KDD 2019 | 时序图中的故障路径预测模型</title><link>https://mp.weixin.qq.com/s/6x-7zKX1taLF-2u117Owcg</link><description></description><content:encoded><![CDATA[KDD 2019 | 时序图中的故障路径预测模型]]></content:encoded><pubDate>Wed, 26 May 2021 18:38:09 +0800</pubDate></item><item><title>中科院自动化所2021年“人工智能”大学生暑期学校招生通知</title><link>https://mp.weixin.qq.com/s/K7n--BUmcfDnDgG4mLtdug</link><description></description><content:encoded><![CDATA[中科院自动化所2021年“人工智能”大学生暑期学校招生通知]]></content:encoded><pubDate>Tue, 25 May 2021 21:09:54 +0800</pubDate></item><item><title>复旦大学 | 大数据学院 | 2021年全国优秀大学生夏令营活动通知</title><link>https://mp.weixin.qq.com/s/bMaKhRG8zG2HJ_37w67seA</link><description></description><content:encoded><![CDATA[复旦大学 | 大数据学院 | 2021年全国优秀大学生夏令营活动通知]]></content:encoded><pubDate>Tue, 25 May 2021 21:09:54 +0800</pubDate></item><item><title>香港中文大学 | 计算机科学与工程系 | 博士研究生招生--提前批面试</title><link>https://mp.weixin.qq.com/s/JE9FhzNkWlBMpv7YfVkm5g</link><description></description><content:encoded><![CDATA[香港中文大学 | 计算机科学与工程系 | 博士研究生招生--提前批面试]]></content:encoded><pubDate>Tue, 25 May 2021 21:09:54 +0800</pubDate></item><item><title>西湖大学 AI 方向博士生招生|导师李子青 (Stan. Z. Li)</title><link>https://mp.weixin.qq.com/s/U5nCppB9V0-Cvc4SuT0M2w</link><description></description><content:encoded><![CDATA[西湖大学 AI 方向博士生招生|导师李子青 (Stan. Z. Li)]]></content:encoded><pubDate>Tue, 25 May 2021 21:09:54 +0800</pubDate></item><item><title>ICML2021 | 图上的Normalization，加速图网络的训练(代码已经公开)</title><link>https://mp.weixin.qq.com/s/Ol6ZcA_wv3JxtovEbAEslw</link><description></description><content:encoded><![CDATA[ICML2021 | 图上的Normalization，加速图网络的训练(代码已经公开)]]></content:encoded><pubDate>Mon, 24 May 2021 14:27:41 +0800</pubDate></item><item><title>2021年3月\图学习\综述论文，19页pdf概述图信号处理、矩阵分解、随机游走和深度学习算法</title><link>https://mp.weixin.qq.com/s/TVt5tPb2Bywv3xTYbUoI0A</link><description></description><content:encoded><![CDATA[2021年3月\图学习\综述论文，19页pdf概述图信号处理、矩阵分解、随机游走和深度学习算法]]></content:encoded><pubDate>Mon, 24 May 2021 14:27:41 +0800</pubDate></item><item><title>在实验中，每当涉及到loss修改都比较恼火:如何控制各部分loss的权重？ 起始训练各loss的数量级不同对收敛存在着哪些影响？</title><link>https://mp.weixin.qq.com/s/ALLaIwxCiOhgtSr7nOuZ3w</link><description></description><content:encoded><![CDATA[在实验中，每当涉及到loss修改都比较恼火:如何控制各部分loss的权重？ 起始训练各loss的数量级不同对收敛存在着哪些影响？]]></content:encoded><pubDate>Sun, 23 May 2021 14:53:42 +0800</pubDate></item></channel></rss>