<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>NewBeeNLP | wechat-feeds</title><link>http://MzIxMzkwNjM2NQ.favicon.privacyhide.com/favicon.ico</link><description>永远有料，永远有趣</description><managingEditor> (hellodword)</managingEditor><pubDate>Mon, 19 Apr 2021 17:22:45 +0800</pubDate><image><url>http://MzIxMzkwNjM2NQ.favicon.privacyhide.com/favicon.ico</url><title>NewBeeNLP | wechat-feeds</title><link>http://MzIxMzkwNjM2NQ.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>[211渣硕] 腾讯/阿里/携程 详细NLP算法实习 面经</title><link>https://mp.weixin.qq.com/s/m1GLDZHLFUJd68QQO4BXkQ</link><description></description><content:encoded><![CDATA[[211渣硕] 腾讯/阿里/携程 详细NLP算法实习 面经]]></content:encoded><pubDate>Mon, 19 Apr 2021 15:36:25 +0800</pubDate></item><item><title>模型化召回在陌陌社交推荐的应用和探索</title><link>https://mp.weixin.qq.com/s/mWb0sOLaQq1FX_3i0AnGTA</link><description></description><content:encoded><![CDATA[模型化召回在陌陌社交推荐的应用和探索]]></content:encoded><pubDate>Mon, 19 Apr 2021 15:36:25 +0800</pubDate></item><item><title>假如易立竞吐槽程序员。。。</title><link>https://mp.weixin.qq.com/s/_ssUd-J4jFYpjrw8fAnh1A</link><description></description><content:encoded><![CDATA[假如易立竞吐槽程序员。。。]]></content:encoded><pubDate>Sun, 18 Apr 2021 14:38:46 +0800</pubDate></item><item><title>LambdaLoss | Google排序学习优化框架</title><link>https://mp.weixin.qq.com/s/fPNRM4kS_Fa6ELCOGELSUw</link><description></description><content:encoded><![CDATA[LambdaLoss | Google排序学习优化框架]]></content:encoded><pubDate>Sun, 18 Apr 2021 14:38:46 +0800</pubDate></item><item><title>水土不服？谈一谈机器学习在金融风控实践经验</title><link>https://mp.weixin.qq.com/s/Xu-D87Fmqr08Ic0V1T2pRw</link><description></description><content:encoded><![CDATA[水土不服？谈一谈机器学习在金融风控实践经验]]></content:encoded><pubDate>Fri, 16 Apr 2021 10:23:21 +0800</pubDate></item><item><title>谁才是Transformer家族中的最强王者？谷歌告诉你答案</title><link>https://mp.weixin.qq.com/s/_vA_zDIMXe4F3wZBd3LavA</link><description></description><content:encoded><![CDATA[谁才是Transformer家族中的最强王者？谷歌告诉你答案]]></content:encoded><pubDate>Fri, 16 Apr 2021 10:23:21 +0800</pubDate></item><item><title>大厂NLP算法工程师，实战指南！</title><link>https://mp.weixin.qq.com/s/NScGHcWB0yN5itVmCCA1tQ</link><description></description><content:encoded><![CDATA[大厂NLP算法工程师，实战指南！]]></content:encoded><pubDate>Thu, 15 Apr 2021 10:17:03 +0800</pubDate></item><item><title>负样本修正：既然数据是模型的上限，就不要破坏这个上限</title><link>https://mp.weixin.qq.com/s/lsR7dBFKfK4fPUugNPRUgA</link><description></description><content:encoded><![CDATA[负样本修正：既然数据是模型的上限，就不要破坏这个上限]]></content:encoded><pubDate>Thu, 15 Apr 2021 10:17:03 +0800</pubDate></item><item><title>谷歌 ICLR 2020 | 向量化召回也需要『预训练』</title><link>https://mp.weixin.qq.com/s/-0e9qp-PoxbTNMzdsRixBA</link><description></description><content:encoded><![CDATA[谷歌 ICLR 2020 | 向量化召回也需要『预训练』]]></content:encoded><pubDate>Wed, 14 Apr 2021 10:21:52 +0800</pubDate></item><item><title>美团算法 SP  | NLP 三面复盘</title><link>https://mp.weixin.qq.com/s/MZOp2VZemIMesfrvmdjspw</link><description></description><content:encoded><![CDATA[美团算法 SP  | NLP 三面复盘]]></content:encoded><pubDate>Tue, 13 Apr 2021 11:05:33 +0800</pubDate></item><item><title>2021年如何科学的“微调”预训练模型？</title><link>https://mp.weixin.qq.com/s/4V3EfdGjDeoTDoANL-bLdA</link><description></description><content:encoded><![CDATA[2021年如何科学的“微调”预训练模型？]]></content:encoded><pubDate>Tue, 13 Apr 2021 11:05:33 +0800</pubDate></item><item><title>独家专访@爱可可-爱生活：如何做好科学研究（干货满满）</title><link>https://mp.weixin.qq.com/s/lEb4JZMqHgHkOHB5Ku2NcQ</link><description></description><content:encoded><![CDATA[独家专访@爱可可-爱生活：如何做好科学研究（干货满满）]]></content:encoded><pubDate>Sun, 11 Apr 2021 21:52:04 +0800</pubDate></item><item><title>互联网高端社畜黑话大全（表情包）</title><link>https://mp.weixin.qq.com/s/Nfl6sZLoZUeXOQ95Ehlo2Q</link><description></description><content:encoded><![CDATA[互联网高端社畜黑话大全（表情包）]]></content:encoded><pubDate>Sat, 10 Apr 2021 10:33:23 +0800</pubDate></item><item><title>复述（paraphrasing）：一种简单暴力的预训练方式</title><link>https://mp.weixin.qq.com/s/un1_lYIaDZSHeNNpqhCsOA</link><description></description><content:encoded><![CDATA[复述（paraphrasing）：一种简单暴力的预训练方式]]></content:encoded><pubDate>Thu, 08 Apr 2021 23:04:38 +0800</pubDate></item><item><title>阿里ESAM：用迁移学习解决召回中的样本偏差</title><link>https://mp.weixin.qq.com/s/LTrpFJUDkUkxRKWkp47V3g</link><description></description><content:encoded><![CDATA[阿里ESAM：用迁移学习解决召回中的样本偏差]]></content:encoded><pubDate>Thu, 08 Apr 2021 23:04:38 +0800</pubDate></item><item><title>从 SimCLR 到 BarLow Twins ，一文了解自监督学习不断打脸的认知发展史</title><link>https://mp.weixin.qq.com/s/-8FWRlz8ubos-vnrXzMWbQ</link><description></description><content:encoded><![CDATA[从 SimCLR 到 BarLow Twins ，一文了解自监督学习不断打脸的认知发展史]]></content:encoded><pubDate>Thu, 08 Apr 2021 10:16:54 +0800</pubDate></item><item><title>收藏｜2021年浅谈多任务学习</title><link>https://mp.weixin.qq.com/s/1GvT5nAqOXssj8nMYmBbmA</link><description></description><content:encoded><![CDATA[收藏｜2021年浅谈多任务学习]]></content:encoded><pubDate>Thu, 08 Apr 2021 10:16:54 +0800</pubDate></item></channel></rss>