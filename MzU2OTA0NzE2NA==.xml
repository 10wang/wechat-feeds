<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>专知 | wechat-feeds</title><link>http://MzU2OTA0NzE2NA.favicon.privacyhide.com/favicon.ico</link><description>专知，为人工智能从业者服务，提供专业可信的人工智能知识与技术服务，让认知协作更快更好！</description><managingEditor> (hellodword)</managingEditor><pubDate>Tue, 16 Mar 2021 17:20:05 +0800</pubDate><image><url>http://MzU2OTA0NzE2NA.favicon.privacyhide.com/favicon.ico</url><title>专知 | wechat-feeds</title><link>http://MzU2OTA0NzE2NA.favicon.privacyhide.com/favicon.ico</link><width>64</width><height>64</height></image><item><title>推荐一个论文复现神器！</title><link>https://mp.weixin.qq.com/s/1o_jE8-OcoO69JKZ3ivRQw</link><description></description><content:encoded><![CDATA[推荐一个论文复现神器！]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>「深度生成建模」最新大综述论文，21页pdf详述GAN、VAE、自回归模型等模型优劣</title><link>https://mp.weixin.qq.com/s/yYklomwleuS7XV-IcwNPTA</link><description></description><content:encoded><![CDATA[「深度生成建模」最新大综述论文，21页pdf详述GAN、VAE、自回归模型等模型优劣]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>【经典书】线性代数，436页pdf</title><link>https://mp.weixin.qq.com/s/KcS8iYy3zUgi2DGf2QR2Sw</link><description></description><content:encoded><![CDATA[【经典书】线性代数，436页pdf]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>【斯坦福NLP-CS224N硬核课】自然语言处理未来与深度学习，81页ppt</title><link>https://mp.weixin.qq.com/s/d1Q-FckpToYeCkBTliL8hA</link><description></description><content:encoded><![CDATA[【斯坦福NLP-CS224N硬核课】自然语言处理未来与深度学习，81页ppt]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>【CVPR2021】加法器神经网络（AdderNet）单图像超分辨率</title><link>https://mp.weixin.qq.com/s/sDkXn6H2kYqk8kDfVpsp8Q</link><description></description><content:encoded><![CDATA[【CVPR2021】加法器神经网络（AdderNet）单图像超分辨率]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>人工智能赋能安全应用案例集白皮书，114页pdf</title><link>https://mp.weixin.qq.com/s/BoV7N5SYH1upQcUqId0zFg</link><description></description><content:encoded><![CDATA[人工智能赋能安全应用案例集白皮书，114页pdf]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>机器学习在信道建模中的应用综述</title><link>https://mp.weixin.qq.com/s/Eep84VSi1r-6bGgbD-mX9g</link><description></description><content:encoded><![CDATA[机器学习在信道建模中的应用综述]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>2021综述论文《小样本/GNN/深度学习/机器学习/知识图谱/NLP/CV》大集合</title><link>https://mp.weixin.qq.com/s/xWwpuXODFK7Zy_VEiftRIg</link><description></description><content:encoded><![CDATA[2021综述论文《小样本/GNN/深度学习/机器学习/知识图谱/NLP/CV》大集合]]></content:encoded><pubDate>Tue, 16 Mar 2021 16:58:45 +0800</pubDate></item><item><title>图神经网络如何落地推荐系统？基于分布式图学习的推荐系统优化之路，带你实战</title><link>https://mp.weixin.qq.com/s/EoWSBwGFzr28XqPVRR0cbQ</link><description></description><content:encoded><![CDATA[图神经网络如何落地推荐系统？基于分布式图学习的推荐系统优化之路，带你实战]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>基于小样本学习的图像分类技术综述(中文版)，19页pdf</title><link>https://mp.weixin.qq.com/s/ZuiKVan3EqOQDR1wjH01WA</link><description></description><content:encoded><![CDATA[基于小样本学习的图像分类技术综述(中文版)，19页pdf]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>【干货书】应用深度学习，425页pdf概述基于案例的深度神经网络理解方法</title><link>https://mp.weixin.qq.com/s/vBrMswfBdCyelznqF0wKeQ</link><description></description><content:encoded><![CDATA[【干货书】应用深度学习，425页pdf概述基于案例的深度神经网络理解方法]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>《深度学习局限性与前沿》教程77页ppt，麻省理工2021深度学习导论课程MIT6.S191课程</title><link>https://mp.weixin.qq.com/s/7gIt1mHWUG8ScDtGCYNVjg</link><description></description><content:encoded><![CDATA[《深度学习局限性与前沿》教程77页ppt，麻省理工2021深度学习导论课程MIT6.S191课程]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>【CVPR2021】基于Transformers 从序列到序列的角度重新思考语义分割</title><link>https://mp.weixin.qq.com/s/bJV6Y8v-uv5UMgXTpjaM3g</link><description></description><content:encoded><![CDATA[【CVPR2021】基于Transformers 从序列到序列的角度重新思考语义分割]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>【WSDM2021-教程】超越概率排序原则：建模文档依赖性，附PPT</title><link>https://mp.weixin.qq.com/s/vPc4kx3pIPGEJ1HiV1dt3w</link><description></description><content:encoded><![CDATA[【WSDM2021-教程】超越概率排序原则：建模文档依赖性，附PPT]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>5G+ICT趋势白皮书（2021年），53页pdf</title><link>https://mp.weixin.qq.com/s/RjyYM_I7YjCgmousQ8Da_Q</link><description></description><content:encoded><![CDATA[5G+ICT趋势白皮书（2021年），53页pdf]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>2021综述论文《小样本/GNN/深度学习/机器学习/知识图谱/NLP/CV》大集合</title><link>https://mp.weixin.qq.com/s/Mi27DvrwLJOtJDBEDL4oiw</link><description></description><content:encoded><![CDATA[2021综述论文《小样本/GNN/深度学习/机器学习/知识图谱/NLP/CV》大集合]]></content:encoded><pubDate>Mon, 15 Mar 2021 15:47:00 +0800</pubDate></item><item><title>裴健等发布首篇「深度学习模型复杂性」综述论文，44页pdf阐述深度学习模型框架、模型规模、优化过程和数据复杂性</title><link>https://mp.weixin.qq.com/s/z8qh3MtifH_xDprXrw33Sg</link><description></description><content:encoded><![CDATA[裴健等发布首篇「深度学习模型复杂性」综述论文，44页pdf阐述深度学习模型框架、模型规模、优化过程和数据复杂性]]></content:encoded><pubDate>Sun, 14 Mar 2021 13:50:00 +0800</pubDate></item><item><title>【干货书】Python 数据科学学习手册，548页pdf</title><link>https://mp.weixin.qq.com/s/Pc_X2xMvDvxMY8BTE8xadQ</link><description></description><content:encoded><![CDATA[【干货书】Python 数据科学学习手册，548页pdf]]></content:encoded><pubDate>Sun, 14 Mar 2021 13:50:00 +0800</pubDate></item><item><title>营销领域人工智能研究综述</title><link>https://mp.weixin.qq.com/s/l2YRKkxnVUSbd1FPT9lzcw</link><description></description><content:encoded><![CDATA[营销领域人工智能研究综述]]></content:encoded><pubDate>Sun, 14 Mar 2021 13:50:00 +0800</pubDate></item><item><title>【CVPR2021】面向视频动作分割的高效网络结构搜索</title><link>https://mp.weixin.qq.com/s/cJ3M955fQXksJeVP8hj6lQ</link><description></description><content:encoded><![CDATA[【CVPR2021】面向视频动作分割的高效网络结构搜索]]></content:encoded><pubDate>Sun, 14 Mar 2021 13:50:00 +0800</pubDate></item></channel></rss>